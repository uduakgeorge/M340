{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trapezoid_method(a,b,N,f):\n",
    "    Nint = int(N)\n",
    "    xvals = np.linspace(a,b,Nint+1)\n",
    "    fvals = f(xvals)\n",
    "    dx = (b-a)/N\n",
    "    return dx/2.*(fvals[0] + fvals[Nint] + 2.*np.sum(fvals[1:Nint])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def secant_method(a,b,N,f):\n",
    "    Nint = int(N)\n",
    "    TNint = 2*N\n",
    "    xvals = np.linspace(a,b,TNint+1)\n",
    "    fvals = f(xvals)\n",
    "    dx = (b-a)/(2.*N)\n",
    "    return dx/3.*(fvals[0] + fvals[TNint] + 2.*np.sum(fvals[2:TNint-1:2]) + 4.*np.sum(fvals[1:TNint:2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Problem 1 **: (10 pts) A particle of mass $m$ moving through a fluid is subjected to viscous resistance $R(v)$, where $v$ is the particle's velocity.  Suppose that relationship between the resistance $R$, velocity $v$, and the time of travel is given by \n",
    "$$\n",
    "t = \\int_{v_{0}}^{v(t)} \\frac{m}{R(u)} du, \n",
    "$$\n",
    "where $v_{0} = v(0)$ is the intial velocity of the particle.  Now suppose that \n",
    "$$\n",
    "R(v) = -R_{\\infty}\\left(\\frac{2}{1 + e^{-v^2/v_{c}^{2}}}-1\\right).\n",
    "$$\n",
    "For a particle of mass $m=1 ~kg$ (kilograms), with $v_{0}=10 ~m/s$ (meters/second), and $v_{c} = 2 ~m/s$ and $R_{\\infty} = 3 ~kg ~m/s^{2}$, using the Trapezoid Method, find the approximate time necessary for the particle to slow to $v(t) = 5 ~ m/s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2** (20 pts): In class, we showed that Simpson's method for finding the integral \n",
    "\n",
    "$$\n",
    "T_{[a,b]}(f) = \\int_{a}^{b} f(x) dx, \n",
    "$$\n",
    "\n",
    "over a mesh $\\left\\{ x_{j} \\right\\}_{j=0}^{2N}$, $x_{j} = a + j\\delta x$, $\\delta x = (b-a)/(2N)$, is found via a series of local approximations via the formula \n",
    "\n",
    "\\begin{align*}\n",
    "\\int_{a}^{b} f(x) dx = & \\sum_{l=0}^{N-1} \\int_{x_{2l}}^{x_{2l+2}} f(x) dx \\\\\n",
    "\\approx & \\sum_{l=0}^{N-1} \\int_{x_{2l}}^{x_{2l+2}} y_{2l+1}(x;x_{2l+1}) dx \n",
    "\\end{align*}\n",
    "\n",
    "where the approximating interpolatory polynomial $y_{2l+1}(x;x_{2l+1})$ is given by \n",
    "\n",
    "$$\n",
    "y_{2l+1}(x;x_{2l+1}) = a_{2l+1}\\left(x-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x-x_{2l+1} \\right) + c_{2l+1}.\n",
    "$$\n",
    "\n",
    "The coefficients $a_{2l+1}$, $b_{2l+1}$, and $c_{2l+1}$ are found via the _interpolation_ requirements\n",
    "\n",
    "\\begin{align*}\n",
    "y_{2l+1}(x_{2l};x_{2l+1}) = & f\\left(x_{2l}\\right) = f_{2l}\\\\\n",
    "y_{2l+1}(x_{2l+1};x_{2l+1}) = & f\\left(x_{2l+1}\\right) = f_{2l+1}\\\\\n",
    "y_{2l+1}(x_{2l+2};x_{2l+1}) = & f\\left(x_{2l+2}\\right) = f_{2l+2}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "* **Part a)** (5 pts) Using the above interpolatory requirements, show that \n",
    "$$\n",
    "a_{2l+1} = \\frac{1}{2(\\delta x)^{2}}\\left(f_{2l} -2f_{2l+1} + f_{2l+2} \\right), ~ b_{2l+1} = \\frac{1}{2\\delta x}\\left(f_{2l+2}-f_{2l} \\right), ~ c_{2l+1} = f_{2l+1}\n",
    "$$\n",
    "\n",
    "* **Part b)** (5 pts) Using the Taylor series expansions\n",
    "\\begin{align*}\n",
    "f_{2l} = f\\left(x_{2l+1}-\\delta x\\right) = f_{2l+1} - f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} - \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + C_{2l+1}(\\delta x)^{4}\\\\\n",
    "f_{2l+2} = f\\left(x_{2l+1}+\\delta x\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} + \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + \\bar{C}_{2l+1}(\\delta x)^{4}\n",
    "\\end{align*}\n",
    "show that \n",
    "\\begin{multline}\n",
    "y_{2l+1}\\left(x;x_{2l+1}\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x-x_{2l+1}\\right) + \\frac{f''(x_{2l+1})}{2}\\left(x-x_{2l+1}\\right)^{2} \\\\\n",
    "+ \\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right) + \\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{2}\n",
    "\\end{multline}\n",
    "\n",
    "* **Part c)** (5 pts) Using the Taylor series expansion\n",
    "$$\n",
    "f(x) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x - x_{2l+1} \\right) + \\frac{1}{2}f''(x_{2l+1})\\left(x - x_{2l+1} \\right)^{2} + \\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{3} + \\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{4}\n",
    "$$\n",
    "show that \n",
    "\\begin{align}\n",
    "\\int_{x_{2l}}^{x_{2l+2}} \\left(f(x) - y_{2l+1}(x;x_{2l+1}) \\right) dx = & \\left(\\frac{2}{5}\\tilde{C}_{2l+1} - \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right) \\right)(\\delta x)^{5}\\\\\n",
    "= & \\hat{C}_{2l+1}\\left(\\delta x \\right)^{5},\n",
    "\\end{align}\n",
    "where we use the relabeling\n",
    "$$\n",
    "\\hat{C}_{2l+1} \\equiv \\frac{2}{5}\\tilde{C}_{2l+1} - \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\n",
    "$$\n",
    "\n",
    "* **Part d)** (5 pts) Letting the global Simpson's approximation be $A_{2N}(f)$ where\n",
    "\\begin{align}\n",
    "A_{2N}(f) = & \\sum_{l=0}^{N-1} \\int_{x_{2l}}^{x_{2l+2}} y_{2l+1}(x;x_{2l+1}) dx \\\\\n",
    "= &\\frac{\\delta x}{3}\\left(f_{0} + f_{2N} + 2\\sum_{l=1}^{N-1}f_{2l} + 4\\sum_{l=0}^{N-1}f_{2l+1} \\right)\n",
    "\\end{align}\n",
    "show that \n",
    "$$\n",
    "T_{[a,b]}(f) - A_{2N}(f) = \\frac{\\hat{C}_{M}}{2}(b-a)(\\delta x)^{4}\n",
    "$$\n",
    "where $\\hat{C}_{M}$ is the biggest of all the constants $\\hat{C}_{2l+1}$ (Note, technically we should have inequalities throughout all of this, but we are only telling a small fib...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Problem 3 ** (10 pts): Choose an example and using the code from Lecture 5 as a model, numerically verify the error analysis we performed for Simpson's method above by generating a log/log plot and a corresponding estimate of the slope of the plotted line.  Note, you may have to use clever choices for $N$ or slicing choices in order to remove nan terms and the like from your slope estimates.  Provide a brief summary of your results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_fun(xvals):\n",
    "    # return values of your test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_test(a,b,f):\n",
    "    tval = \n",
    "    Nvals = np.array([])\n",
    "    Evals = np.zeros()\n",
    "    for jj in xrange(0,):\n",
    "        Evals[jj] = \n",
    "    xvals = np.log10(Nvals)\n",
    "    plt.plot(xvals,Evals)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    novals = Evals.size\n",
    "    slopes = \n",
    "    print np.min(slopes)\n",
    "    print np.max(slopes)\n",
    "    print np.mean(slopes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

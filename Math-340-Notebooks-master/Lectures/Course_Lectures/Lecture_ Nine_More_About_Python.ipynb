{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Text and File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a cool thing about this is that we can work with files in a very natural way.  For example, I can import text files such as 'beyonce.txt' and then print the lines by writing the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line number is 1.\n",
      "Nothing else seems to hurt like the smile on your face when it is only in my memory.  \r\n",
      "\n",
      "The line number is 2.\n",
      "I am the dragon breathing fire, beautiful mane, I'm the lion.\r\n",
      "\n",
      "The line number is 3.\n",
      "Our love was stronger than your pride. \r\n",
      "\n",
      "The line number is 4.\n",
      "You don't deserve my tears, I guess that's why they ain't there. \n"
     ]
    }
   ],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "count = 0\n",
    "for line in queen_bee:\n",
    "    count += 1\n",
    "    print \"The line number is %d.\" % count\n",
    "    print line\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that yes, the text file is treated as a series of lines. And in terms of reading the lines, that is also straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nothing el', 'e ', 'eem', ' to hurt like the ', 'mile on your face when it i', ' only in my memory.']\n",
      "Nothing else seems to hurt like the smile on your face when it is only in my memory.\n",
      "\n",
      "[\"I am the dragon breathing fire, beautiful mane, I'm the lion.\"]\n",
      "I am the dragon breathing fire, beautiful mane, I'm the lion.\n",
      "\n",
      "['Our love wa', ' ', 'tronger than your pride.']\n",
      "Our love was stronger than your pride.\n",
      "\n",
      "[\"You don't de\", 'erve my tear', ', I gue', '', \" that'\", \" why they ain't there.\"]\n",
      "You don't deserve my tears, I guess that's why they ain't there.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split('s') # Turns the line into a list of words\n",
    "    print words\n",
    "    print line\n",
    "    print\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can then readily start answering various questions.  Like, what if we want to print out only those lines that contain the word 'fire' in them.  Then what we do is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split('s') # Turns the line into a list of words by breaking line up across spaces.\n",
    "    if \"fire\" in words:\n",
    "        print line\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that didn't do anything.  Why not?  Write the code that will actually do something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split('s') # Turns the line into a list of words by breaking line up across spaces.\n",
    "    if \"fire,\" in words:\n",
    "        print line\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So maybe we also want to process each line not just into words, but remove punctuation marks. How would you do this for just commas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am the dragon breathing fire, beautiful mane, I'm the lion.\n"
     ]
    }
   ],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split() # Turns the line into a list of words by breaking line up across spaces.\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        if \",\" in word:\n",
    "            words[cnt] = word[0:len(word)-1] # Thus, we change the list element, not the word itself.\n",
    "        cnt+=1\n",
    "    if \"fire\" in words:\n",
    "        print line\n",
    "\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a function whose job it is to provide a histogram of the letters in a given body of text.  Along the way, we need to build helper functions which the main function will call.  But let's get a template of an idea down first.  \n",
    "\n",
    "We want to pass in a filename, say \"juliet.txt\" or \"beyonce.txt\", and then get a plot of the frequency with which different letters appear.  We should return the distribution as a list.\n",
    "\n",
    "But okay, we want to do a frequency analysis of letters.  That means we want to get rid of punctuation.  So we need to develop a helper function which takes a list of words, strips the punctuation while keeping all the letters.  \n",
    "\n",
    "Now note, because we have Shakespeare to analyze, we have to allow that things like apostrophes can come at almost any point in the word.  So be careful.  Your helper function should return a list of words with no punctuation.  You will need to use the string helper function\n",
    "\n",
    "`word.isalnum()`\n",
    "\n",
    "which tests if a string consists only of alpha/numeric characters.  Also, don't forget about good stuff like \n",
    "\n",
    " `word.append(char)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punc_remove(words):\n",
    "    ind = 0\n",
    "    for word in words:\n",
    "            # Here is where you need to start introducing code.\n",
    "            if word.isalnum() == False:\n",
    "                wordt = []\n",
    "                for char in word:\n",
    "                    if char.isalnum():\n",
    "                        wordt.append(char)\n",
    "                delimeter = \"\"\n",
    "                words[ind] = delimeter.join(wordt) # Note the absence of a return statement since we rely\n",
    "                                                   # on pass by reference to modify words both within\n",
    "                                                   # the function and then used afterwards in its \n",
    "                                                   # modified form.\n",
    "            ind+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to think about lower and upper case.  So, we would like a helper function which takes a list of words and converts everything to upper case.  Note, you will need to make use of the string helper function\n",
    "\n",
    "`word.upper()`\n",
    "\n",
    "which makes every character in a string uppercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_upper(words):\n",
    "    ind = 0\n",
    "    for word in words:\n",
    "        words[ind] = word.upper()\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now the hard part.  We need to build a helper function which is able to take a given string or word, and a list which is keeping track of the frequency of occurences of each letter.  To do this, we need to make use of what are called _ dictionaries _.  A good way to see the use of them is to realize that if I give you a word, and you wanted to keep track of which letters appeared in it, you would probably think to write something like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letter_cnt(word,freq):\n",
    "    for let in word:\n",
    "        if let == 'A': freq[0]+=1\n",
    "        elif let == 'B': freq[1]+=1\n",
    "        elif let == 'C': freq[2]+=1\n",
    "        elif let == 'D': freq[3]+=1\n",
    "        elif let == 'E': freq[4]+=1\n",
    "        elif let == 'F': freq[5]+=1\n",
    "        elif let == 'G': freq[6]+=1\n",
    "        elif let == 'H': freq[7]+=1\n",
    "        elif let == 'I': freq[8]+=1\n",
    "        elif let == 'J': freq[9]+=1\n",
    "        elif let == 'K': freq[10]+=1\n",
    "        elif let == 'L': freq[11]+=1\n",
    "        elif let == 'M': freq[12]+=1\n",
    "        elif let == 'N': freq[13]+=1\n",
    "        elif let == 'O': freq[14]+=1\n",
    "        elif let == 'P': freq[15]+=1\n",
    "        elif let == 'Q': freq[16]+=1\n",
    "        elif let == 'R': freq[17]+=1\n",
    "        elif let == 'S': freq[18]+=1\n",
    "        elif let == 'T': freq[19]+=1\n",
    "        elif let == 'U': freq[20]+=1\n",
    "        elif let == 'V': freq[21]+=1   \n",
    "        elif let == 'W': freq[22]+=1\n",
    "        elif let == 'X': freq[23]+=1\n",
    "        elif let == 'Y': freq[24]+=1\n",
    "        elif let == 'Z': freq[25]+=1        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, um, just no.  This is not how anyone in the modern era should code.  Ever.  This is not good code.  To, radically, improve it, we use a dictionary.  The idea behind a dictionary is to generalize the notion of a list such that you no longer have integer valued indices to refer to elements.  Instead, you have *keys*.  So following the book, we can build a dictionary whose keys are universities, and whose *values* are mascot names.  We do this by writing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mascots={'CSUN': 'Matty_Matador',\n",
    "         'Florida':'Gators',\n",
    "         'Irvine':'Anteater'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if we type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matty_Matador\n",
      "Anteater\n"
     ]
    }
   ],
   "source": [
    "print mascots['CSUN']\n",
    "print mascots['Irvine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why is this useful?  Well, let's suppose that we want to keep track of how many times each letter is used.  A good way to do this would be to build a dictionary with letters for keys and the count as values.  To do this, we do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = list(string.uppercase[:26])\n",
    "freq_d = dict()\n",
    "for let in alpha: freq_d[let] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print freq_d.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does this do?  Well, first, we want a list of all possible upper case letters.  That we do with the list alpha, which being more explicit we see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "print list(string.uppercase[:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letter_cnt(word,freq_d):\n",
    "    for let in word: freq_d[let]+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def txt_cntr(file_name):\n",
    "    fname = open(file_name)\n",
    "    alpha = list(string.uppercase[:26])\n",
    "    freq_d = dict()\n",
    "    freq = np.zeros(26)\n",
    "    \n",
    "    for let in alpha: freq_d[let] = 0\n",
    "        \n",
    "    for line in fname:\n",
    "        line = line.rstrip()\n",
    "        words = line.split()\n",
    "        punc_remove(words)\n",
    "        make_upper(words)\n",
    "        for word in words:\n",
    "            letter_cnt(word,freq_d)\n",
    "    \n",
    "    ind = 0\n",
    "    for let in alpha:\n",
    "        freq[ind] = freq_d[let]\n",
    "        ind += 1\n",
    "    \n",
    "    fname.close()\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 26 artists>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADCNJREFUeJzt3VGInWV+x/Hvr6u9US8iDiFY06kgC1JohMEWVhbLdhdX\nL1Qo0lxISrfEC1cU9qLBmxVKIZTV7U2RRgybgmtZUKugtLgi2IUiO5Gg0bB1WSI1xCTihe5VUf+9\nmFc6DTOZM+ecyZnzn+8HwnnP875nzv/hNT8fn3nex1QVkqT59zuzLkCSNB0GuiQ1YaBLUhMGuiQ1\nYaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhNXXM4vu+6662pxcfFyfqUkzb3jx49/XFULG113WQN9cXGR\n5eXly/mVkjT3knwwynVOuUhSEwa6JDVhoEtSEwa6JDVhoEtSEwa6JDVhoEtSEwa6JDVhoEtSE5f1\nSdGdavHQyyNdd/rwXVtciaTOHKFLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBL\nUhMGuiQ1sWGgJ7khyetJ3kvybpKHh/bHkpxJcmL4c+fWlytJWs8oe7l8Dvygqt5Kcg1wPMmrw7kf\nV9WPtq48SdKoNgz0qjoLnB2OP0tyCrh+qwuTJG3OpubQkywCtwBvDk0PJXk7ydEku6ZcmyRpE0YO\n9CRXA88Bj1TVp8CTwI3APlZG8I+v87mDSZaTLF+4cGEKJUuS1jJSoCe5kpUwf6aqngeoqnNV9UVV\nfQk8Bdy61mer6khVLVXV0sLCwrTqliRdZJRVLgGeBk5V1ROr2vesuuxe4OT0y5MkjWqUVS7fAO4H\n3klyYmh7FNifZB9QwGnggS2pUJI0klFWufwCyBqnXpl+OZKkcfmkqCQ1YaBLUhMGuiQ1YaBLUhMG\nuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1\nYaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBL\nUhMbBnqSG5K8nuS9JO8meXhovzbJq0neH153bX25kqT1jDJC/xz4QVXdDPwJ8GCSm4FDwGtVdRPw\n2vBekjQjGwZ6VZ2tqreG48+AU8D1wN3AseGyY8A9W1WkJGljm5pDT7II3AK8CeyuqrPDqY+A3et8\n5mCS5STLFy5cmKBUSdKljBzoSa4GngMeqapPV5+rqgJqrc9V1ZGqWqqqpYWFhYmKlSStb6RAT3Il\nK2H+TFU9PzSfS7JnOL8HOL81JUqSRjHKKpcATwOnquqJVadeAg4MxweAF6dfniRpVFeMcM03gPuB\nd5KcGNoeBQ4DP0vyPeAD4L6tKVGSNIoNA72qfgFkndPfmm45kqRx+aSoJDVhoEtSEwa6JDVhoEtS\nEwa6JDVhoEtSEwa6JDVhoEtSEwa6JDVhoEtSE6Ps5SJph1s89PJI150+fNcWV6JLcYQuSU0Y6JLU\nhIEuSU0Y6JLUhIEuSU0Y6JLUhIEuSU0Y6JLUhIEuSU0Y6JLUhIEuSU0Y6JLUhIEuSU0Y6JLUhIEu\nSU0Y6JLUhIEuSU0Y6JLUxIaBnuRokvNJTq5qeyzJmSQnhj93bm2ZkqSNjDJC/wlwxxrtP66qfcOf\nV6ZbliRpszYM9Kp6A/jkMtQiSZrAJHPoDyV5e5iS2TW1iiRJY7lizM89CfwtUMPr48BfrXVhkoPA\nQYC9e/eO+XWapcVDL294zenDd12GSiRdylgj9Ko6V1VfVNWXwFPArZe49khVLVXV0sLCwrh1SpI2\nMFagJ9mz6u29wMn1rpUkXR4bTrkkeRa4HbguyYfAD4Hbk+xjZcrlNPDAFtYoSRrBhoFeVfvXaH56\nC2qRJE3AJ0UlqQkDXZKaGHfZotTSZpZojnLt6uu3mstL5Qhdkpow0CWpCQNdkpow0CWpCQNdkpow\n0CWpCQNdkpow0CWpCQNdkpow0CWpCQNdkpow0CWpCQNdkpow0CWpCQNdkppwP/QdyH2zBf5z0JEj\ndElqwkCXpCYMdElqwkCXpCYMdElqwkCXpCbmZtniKEuswGVWknYuR+iS1ISBLklNGOiS1MSGgZ7k\naJLzSU6uars2yatJ3h9ed21tmZKkjYwyQv8JcMdFbYeA16rqJuC14b0kaYY2DPSqegP45KLmu4Fj\nw/Ex4J4p1yVJ2qRx59B3V9XZ4fgjYPeU6pEkjWniX4pWVQG13vkkB5MsJ1m+cOHCpF8nSVrHuIF+\nLskegOH1/HoXVtWRqlqqqqWFhYUxv06StJFxA/0l4MBwfAB4cTrlSJLGNcqyxWeB/wS+nuTDJN8D\nDgPfTvI+8GfDe0nSDG24l0tV7V/n1LemXIskaQI+KSpJTRjoktSEgS5JTczNfujSOEbZR9899LXa\nPP+/FxyhS1ITBrokNWGgS1ITBrokNWGgS1ITBrokNeGyRUlTN89L/+aZI3RJasJAl6QmDHRJasJA\nl6QmDHRJasJAl6QmDHRJasJ16Jorbocrrc8RuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1YaBLUhMGuiQ1\nYaBLUhMGuiQ1YaBLUhMGuiQ1MdFeLklOA58BXwCfV9XSNIqSJG3eNDbn+tOq+ngKP0eSNAGnXCSp\niUlH6AX8PMkXwD9V1ZGLL0hyEDgIsHfv3gm/TmtxS1lJMPkI/baq2gd8F3gwyTcvvqCqjlTVUlUt\nLSwsTPh1kqT1TBToVXVmeD0PvADcOo2iJEmbN3agJ7kqyTVfHQPfAU5OqzBJ0uZMMoe+G3ghyVc/\n56dV9W9TqUqStGljB3pV/Qb4oynWIkmagMsWJakJA12SmpjGk6I7kmu/JW03jtAlqQkDXZKaMNAl\nqQkDXZKaMNAlqQkDXZKaMNAlqQnXoW9Do6xxB9e5a+fyOZC1OUKXpCYMdElqwkCXpCYMdElqwkCX\npCYMdElqou2yRZc1SfPDv6/T4Qhdkpow0CWpCQNdkpow0CWpCQNdkpow0CWpCQNdkppouw59s1wH\nOxs7aavgndRXzYYjdElqwkCXpCYMdElqYqJAT3JHkl8l+XWSQ9MqSpK0eWMHepKvAf8IfBe4Gdif\n5OZpFSZJ2pxJRui3Ar+uqt9U1f8A/wLcPZ2yJEmbNUmgXw/896r3Hw5tkqQZSFWN98Hkz4E7quqv\nh/f3A39cVd+/6LqDwMHh7deBX13ix14HfDxWQfPHvvZkX3uadV9/v6oWNrpokgeLzgA3rHr/e0Pb\n/1NVR4Ajo/zAJMtVtTRBTXPDvvZkX3ual75OMuXyS+CmJH+Q5HeBvwBemk5ZkqTNGnuEXlWfJ/k+\n8O/A14CjVfXu1CqTJG3KRHu5VNUrwCtTqgVGnJppwr72ZF97mou+jv1LUUnS9uKj/5LUxLYJ9J20\njUCS00neSXIiyfKs65mmJEeTnE9yclXbtUleTfL+8LprljVOyzp9fSzJmeHenkhy5yxrnIYkNyR5\nPcl7Sd5N8vDQ3u6+XqKvc3Fft8WUy7CNwH8B32blAaVfAvur6r2ZFrZFkpwGlqqq3RreJN8Efgv8\nc1X94dD298AnVXV4+Jf1rqr6m1nWOQ3r9PUx4LdV9aNZ1jZNSfYAe6rqrSTXAMeBe4C/pNl9vURf\n72MO7ut2GaG7jUATVfUG8MlFzXcDx4bjY6z8BZl76/S1nao6W1VvDcefAadYeSq83X29RF/nwnYJ\n9J22jUABP09yfHiStrvdVXV2OP4I2D3LYi6Dh5K8PUzJzP00xGpJFoFbgDdpfl8v6ivMwX3dLoG+\n09xWVftY2anyweE/3XeEWpnjm/0839Z5ErgR2AecBR6fbTnTk+Rq4Dngkar6dPW5bvd1jb7OxX3d\nLoE+0jYCXVTVmeH1PPACK1NOnZ0b5ia/mqM8P+N6tkxVnauqL6rqS+ApmtzbJFeyEnDPVNXzQ3PL\n+7pWX+flvm6XQN8x2wgkuWr4ZQtJrgK+A5y89Kfm3kvAgeH4APDiDGvZUl8F3OBeGtzbJAGeBk5V\n1ROrTrW7r+v1dV7u67ZY5QIwLAP6B/5vG4G/m3FJWyLJjayMymHlSd2fduprkmeB21nZne4c8EPg\nX4GfAXuBD4D7qmruf5m4Tl9vZ+U/yws4DTywap55LiW5DfgP4B3gy6H5UVbmllvd10v0dT9zcF+3\nTaBLkiazXaZcJEkTMtAlqQkDXZKaMNAlqQkDXZKaMNAlqQkDXZKaMNAlqYn/BWHaPz194CpxAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x76449d4c1f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_cnt = txt_cntr('beyonce.txt')\n",
    "lvals = np.linspace(1,26,26)\n",
    "plt.bar(lvals,freq_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
